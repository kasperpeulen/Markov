\exercise{1.1.3i}{Let $X$ be a random variable with values in a countable set $I$. Let $Y_1,Y_2,...$ be a sequence of independent random variables, uniformly distributed on $[0,1]$. Suppose we are given a function $G: I \times [0,1] \to I$ and define inductively $X_{n+1}=G(X_n,Y_{n+1})$. Show that $(X_n)_{n\geq 0}$ is a Markov chain and express its transition matrix $P$ in terms of $G$.}

\beginproof
We first show that $(X_n)_{n\geq 0}$ is a Markov chain. 
\begin{align*}
P(X_{n+1} = i_{n+1} | X_0 = i_0,...,X_n=i_n) &= P( G(X_n,Y_{n+1}) = i_{n+1} | X_0 =i_0,...,X_n=i_n ) \\
&= G(i_n ,Y_{n+1}) = i_{n+1} | X_0 = i_0 ,...,X_{n-1}=i_{n-1})
\end{align*}

Note that $Y_{n+1}$ and $X_k$ are independent for $k=0,...,n-1$. This follows from the definition of $X_k$. It only depends on $Y_0,...,Y_k$. Therefore, according to exercise 1.1.1, we can deduce the following:
\begin{align*}
G(i_n ,Y_{n+1}) = i_{n+1} | X_0 = i_0 ,...,X_{n-1}=i_{n-1} & = P(G(i_n,Y_{n+1})=i_{n+1}) \\
&= P (G(X_n, Y_{n+1}) = i_{n+1} | X_n = i_n) \\
&= P (X_{n+1} =i_{n+1} | X_n = i_n)
\end{align*}

So this proves that it is Markov Chain. The matrix entry $p_{ij}$ will have value $P (X_{n+1} =j | X_n = i)$.
\endproof